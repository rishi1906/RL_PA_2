{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "# Replace with your actual API key\n",
        "api_key = \"17dab9d1bbdc37c41831799a4b0b50d3e97400c5\"\n",
        "project_name='RWABS1'\n",
        "# Login to Weights & Biases\n",
        "wandb.login(key=api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlW33Sjz2WUd",
        "outputId": "8c258d9d-671e-4d47-c0e7-dc711de49c86"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.44.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrishi1906\u001b[0m (\u001b[33miitm_aero\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (16, 10)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "torch.manual_seed(0)\n",
        "import base64\n",
        "import io  # For visualization\n",
        "from gym.wrappers.monitoring import video_recorder\n",
        "from IPython.display import HTML\n",
        "from IPython import display\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "r9eE0OjXWWW0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJTy0fUIWY_r",
        "outputId": "517914a1-bf7f-46e3-fb81-62c09406640b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('Acrobot-v1')\n",
        "env.seed(0)\n",
        "state_shape = env.observation_space.shape[0]\n",
        "action_shape = env.action_space.n\n",
        "# print('observation space:', env.observation_space)\n",
        "# print('action space:', env.action_space)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hse5VDflWeUk",
        "outputId": "075f14bc-f990-44be-cad1-eaabe48997fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Policy(nn.Module):\n",
        "    def __init__(self, state_size=6, action_size=3, hidden_size=32):\n",
        "        super(Policy, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, action_size)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = self.fc2(x)\n",
        "        # we just consider 1 dimensional probability of action\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "    def act(self, state):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        probs = self.forward(state).cpu()\n",
        "        model = Categorical(probs)\n",
        "        action = model.sample()\n",
        "        return action.item(), model.log_prob(action)\n"
      ],
      "metadata": {
        "id": "9FP5uDjrt2AC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Baseline(nn.Module):\n",
        "    def __init__(self, state_size, hidden_size=32):\n",
        "        super(Baseline, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tB2in_BDt4iX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T1B1nA1J0Fxa"
      },
      "outputs": [],
      "source": [
        "def reinforce(env, policy, optimizer, baseline, baseline_optimizer, n_episodes=1000, max_t=1000, gamma=0.99, print_every=100):\n",
        "    scores_deque = deque(maxlen=100)\n",
        "    scores = []\n",
        "    average_scores_epsgrdy = []\n",
        "    episode_list_epsgrdy = []\n",
        "    for e in range(1, n_episodes):\n",
        "        saved_log_probs = []\n",
        "        rewards = []\n",
        "        states = []\n",
        "        state = env.reset()\n",
        "        for t in range(max_t):\n",
        "            states.append(state)\n",
        "            action, log_prob = policy.act(state)\n",
        "            saved_log_probs.append(log_prob)\n",
        "            state, reward, done, _ = env.step(action)  # Unpack five values\n",
        "            rewards.append(reward)\n",
        "            if done:  # Check for both done and truncated\n",
        "                break\n",
        "        scores_deque.append(sum(rewards))\n",
        "        scores.append(sum(rewards))\n",
        "\n",
        "\n",
        "        average_score = np.mean(scores_window)\n",
        "        average_scores_epsgrdy.append(average_score)\n",
        "\n",
        "        wandb.log({'average_score': average_score})\n",
        "\n",
        "        episode_list_epsgrdy.append(e)\n",
        "\n",
        "        discounts = [gamma ** i for i in range(len(rewards) + 1)]\n",
        "        R = sum([a * b for a, b in zip(discounts, rewards)])\n",
        "\n",
        "        # Calculate the baseline\n",
        "        baseline_values = []\n",
        "        for state_in_trajectory in states:\n",
        "            state_tensor = torch.from_numpy(state_in_trajectory).float().unsqueeze(0).to(device)\n",
        "            baseline_value = baseline(state_tensor)\n",
        "            baseline_values.append(baseline_value)\n",
        "        baseline_values = torch.cat(baseline_values, dim=0).requires_grad_()\n",
        "\n",
        "        # Calculate the policy loss\n",
        "        policy_loss = []\n",
        "        for log_prob, baseline_value in zip(saved_log_probs, baseline_values):\n",
        "            policy_loss.append(-(log_prob * (R - baseline_value)))\n",
        "        policy_loss = torch.cat(policy_loss).sum()\n",
        "\n",
        "        # Update the policy\n",
        "        optimizer.zero_grad()\n",
        "        policy_loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the baseline\n",
        "        baseline_optimizer.zero_grad()\n",
        "        baseline_loss = ((baseline_values - R) ** 2).mean()\n",
        "        baseline_loss.backward()\n",
        "        baseline_optimizer.step()\n",
        "\n",
        "        if e % print_every == 0:\n",
        "            print('Episode {}\\tAverage Score: {:.2f}'.format(e, np.mean(scores_deque)))\n",
        "        if e % 100 == 0  and np.mean(scores_window) >= -100:\n",
        "            wandb.log({\"episode_no\": e})\n",
        "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(e, np.mean(scores_window)))\n",
        "            break\n",
        "\n",
        "    return episode_list_epsgrdy, average_scores_epsgrdy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=project_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "KxvEp_SBuD2-",
        "outputId": "65f28143-0d10-4032-a597-e42aa789f581"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240409_030517-tscwcwff</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/iitm_aero/RWBCS1/runs/tscwcwff' target=\"_blank\">devout-cosmos-73</a></strong> to <a href='https://wandb.ai/iitm_aero/RWBCS1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/iitm_aero/RWBCS1' target=\"_blank\">https://wandb.ai/iitm_aero/RWBCS1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/iitm_aero/RWBCS1/runs/tscwcwff' target=\"_blank\">https://wandb.ai/iitm_aero/RWBCS1/runs/tscwcwff</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/iitm_aero/RWBCS1/runs/tscwcwff?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x79980c352080>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# policy = Policy().to(device)\n",
        "# optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
        "# baseline = Baseline(state_size=env.observation_space.shape[0]).to(device)\n",
        "# baseline_optimizer = optim.Adam(baseline.parameters(), lr=1e-2)\n",
        "# scores = reinforce(env, policy, optimizer, baseline, baseline_optimizer, n_episodes=2000)\n",
        "# wandb.finish()  # Finish wandb run"
      ],
      "metadata": {
        "id": "N77wn3PRtyXB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sweep_config = {\n",
        "#     'method': 'grid',\n",
        "#     'metric': {\n",
        "#       'name': 'Average Reward',\n",
        "#       'goal': 'maximize'\n",
        "#     },\n",
        "#     'parameters': {\n",
        "#         'hidden_size': {\n",
        "#             'values': [32,64,128]\n",
        "#         },\n",
        "#         'max_t': {\n",
        "#             'values': [500, 1000, 1500]\n",
        "#         },\n",
        "#         'lr': {\n",
        "#             'values': [1e-5, 1e-3,1e-4]\n",
        "#         }\n",
        "#     }\n",
        "# }"
      ],
      "metadata": {
        "id": "Sn8tdcXc1Gte"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'metric': {\n",
        "      'name': 'Average Reward',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'state_size': {\n",
        "            'values': [state_shape]\n",
        "        },\n",
        "        'action_size': {\n",
        "            'values': [action_shape]\n",
        "        },\n",
        "        'hidden_size': {\n",
        "            'values': [32,64,128]\n",
        "        },\n",
        "        'max_t': {\n",
        "            'values': [500, 1000, 1500]\n",
        "        },\n",
        "        'lr': {\n",
        "            'values': [1e-2, 1e-3,1e-4]\n",
        "        },\n",
        "        'baseline_lr': {\n",
        "            'values': [1e-3]\n",
        "        },\n",
        "        'gamma': {\n",
        "            'values': [0.99]\n",
        "        },\n",
        "        'alpha': {\n",
        "            'values': [0.01, 0.001, 0.0001]\n",
        "        },\n",
        "        'n_episodes': {\n",
        "            'values': [5000]\n",
        "        },\n",
        "        \"max_t\":{\n",
        "            'values': [1000]\n",
        "        },\n",
        "         \"print_every\": {\n",
        "             'values': [100]\n",
        "         }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "odkefnoFuLrA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a new sweep\n",
        "sweep_id = wandb.sweep(sweep_config,  project=project_name)\n",
        "max_sweep_run = 5 #update it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cc71a1-7920-45be-e57e-d974d054603f",
        "id": "4676rEiOuQ-o"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 2yx9nidn\n",
            "Sweep URL: https://wandb.ai/iitm_aero/RWBCS1/sweeps/2yx9nidn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    with wandb.init() as run:\n",
        "        # Get the hyperparameters for this run\n",
        "        config = wandb.config\n",
        "        # # Initialize the environment and seed\n",
        "        # env = gym.make('Acrobot-v1')\n",
        "        # env.seed(0)\n",
        "\n",
        "        # # Get the state and action sizes for the Acrobot-v1 environment\n",
        "        # state_size = env.observation_space.shape[0]  # 6 dimensions\n",
        "        # action_size = env.action_space.n  # 3 actions\n",
        "\n",
        "        # Create the policy network with the specified hyperparameters\n",
        "        policy = Policy(state_size=state_shape, action_size=action_shape, hidden_size=config.hidden_size).to(device)\n",
        "        optimizer = optim.Adam(policy.parameters(), lr=config.lr)\n",
        "\n",
        "        # Create the baseline network with the specified hyperparameters\n",
        "        baseline = Baseline(state_size=state_shape).to(device)\n",
        "        baseline_optimizer = optim.Adam(baseline.parameters(), lr=config.baseline_lr)\n",
        "\n",
        "        # Run the REINFORCE algorithm with the specified hyperparameters\n",
        "        scores = reinforce(env, policy, optimizer, baseline, baseline_optimizer, n_episodes=config.n_episodes, max_t=config.max_t, gamma=config.gamma, print_every=config.print_every)\n",
        "\n",
        "        # # Check if the environment is solved\n",
        "        # if np.mean(scores[-100:]) >= -100:  # Adjust the threshold as needed\n",
        "        #     print(f'Environment {env.unwrapped.spec.id} solved in {e - 100:d} episodes!\\tAverage Score: {np.mean(scores_deque):.2f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Log the final score as a summary metric\n",
        "        run.summary[\"final_score\"] = np.mean(scores[-100:])\n",
        "\n",
        "        # # Finish the wandb run\n",
        "        # run.finish()\n",
        "\n",
        "        # # Return any necessary values or metrics\n",
        "        # return np.mean(scores[-100:])"
      ],
      "metadata": {
        "id": "ec7NSC4VcNhq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, main, count=max_sweep_run)"
      ],
      "metadata": {
        "id": "47lgJGSB0cp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}