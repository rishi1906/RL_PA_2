{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec6a1f3a23304cfe8b3384c2133fb8d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf601a707ebf4e329c2745604716bdc3",
              "IPY_MODEL_6889d464afb34373ac5e976cb728ab39"
            ],
            "layout": "IPY_MODEL_8036d050cadd4e3ea11b0af6c3515db1"
          }
        },
        "cf601a707ebf4e329c2745604716bdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f8d30d7a88147fe8dab0700e9bbe82b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_10597fc5e9a343e786cacd4cc5cb6cb6",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "6889d464afb34373ac5e976cb728ab39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f57fc3d4a76405591b06b214e331ef0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29e6a8d0c8944a1c8553f7f3fe610a6e",
            "value": 1
          }
        },
        "8036d050cadd4e3ea11b0af6c3515db1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f8d30d7a88147fe8dab0700e9bbe82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10597fc5e9a343e786cacd4cc5cb6cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f57fc3d4a76405591b06b214e331ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29e6a8d0c8944a1c8553f7f3fe610a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "# Replace with your actual API key\n",
        "api_key = \"17dab9d1bbdc37c41831799a4b0b50d3e97400c5\"\n",
        "project_name='RBCS2'\n",
        "# Login to Weights & Biases\n",
        "wandb.login(key=api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlW33Sjz2WUd",
        "outputId": "172be373-23d4-46b0-ad40-26df6766ef72"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.44.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (16, 10)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "torch.manual_seed(0)\n",
        "import base64\n",
        "import io  # For visualization\n",
        "from gym.wrappers.monitoring import video_recorder\n",
        "from IPython.display import HTML\n",
        "from IPython import display\n",
        "import glob\n",
        "import datetime"
      ],
      "metadata": {
        "id": "r9eE0OjXWWW0"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)"
      ],
      "metadata": {
        "id": "wJTy0fUIWY_r"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "env.seed(0)\n",
        "state_shape = env.observation_space.shape[0]\n",
        "action_shape = env.action_space.n\n",
        "# print('observation space:', env.observation_space)\n",
        "# print('action space:', env.action_space)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hse5VDflWeUk",
        "outputId": "6a2ff5db-095c-4c98-84e3-303559a7a432"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Policy(nn.Module):\n",
        "    def __init__(self, state_size=4, action_size=2, hidden_size=32):\n",
        "        super(Policy, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, action_size)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = self.fc2(x)\n",
        "        # we just consider 1 dimensional probability of action\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "    def act(self, state):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        if state.shape[1] != 4:  # Check if the state tensor has the expected shape\n",
        "            state = state.view(1, 4)  # Reshape the state tensor to (1, 4)\n",
        "        probs = self.forward(state).cpu()\n",
        "        model = Categorical(probs)\n",
        "        action = model.sample()\n",
        "        return action.item(), model.log_prob(action)"
      ],
      "metadata": {
        "id": "R2uE3MgCNh5V"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Baseline(nn.Module):\n",
        "    def __init__(self, state_size, hidden_size=32):\n",
        "        super(Baseline, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dRKyEts2NlN6"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "Mw9LDqVmPwkK"
      },
      "outputs": [],
      "source": [
        "def reinforce(env, policy, optimizer, baseline, baseline_optimizer, n_episodes=1000, max_t=1000, gamma=1.0, print_every=100):\n",
        "    scores_window = deque(maxlen=100)\n",
        "    scores = []\n",
        "    for e in range(1, n_episodes):\n",
        "        saved_log_probs = []\n",
        "        rewards = []\n",
        "        states = []\n",
        "        state = env.reset()\n",
        "        average_scores_epsgrdy = []\n",
        "        episode_list_epsgrdy = []\n",
        "        for t in range(max_t):\n",
        "            states.append(state)\n",
        "            action, log_prob = policy.act(state)\n",
        "            saved_log_probs.append(log_prob)\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            rewards.append(reward)\n",
        "            if done:\n",
        "                break\n",
        "        scores_window.append(sum(rewards))\n",
        "        scores.append(sum(rewards))\n",
        "\n",
        "        average_score = np.mean(scores_window)\n",
        "        average_scores_epsgrdy.append(average_score)\n",
        "\n",
        "        wandb.log({'average_score': average_score})\n",
        "\n",
        "        episode_list_epsgrdy.append(e)\n",
        "\n",
        "\n",
        "        discounts = [gamma ** i for i in range(len(rewards) + 1)]\n",
        "        R = sum([a * b for a, b in zip(discounts, rewards)])\n",
        "\n",
        "        # Calculate the baseline\n",
        "        baseline_values = []\n",
        "        for state_in_trajectory in states:\n",
        "            state_tensor = torch.from_numpy(state_in_trajectory).float().unsqueeze(0).to(device)\n",
        "            baseline_value = baseline(state_tensor)\n",
        "            baseline_values.append(baseline_value)\n",
        "        baseline_values = torch.cat(baseline_values, dim=0).requires_grad_()\n",
        "\n",
        "        # Calculate the policy loss\n",
        "        policy_loss = []\n",
        "        for log_prob, baseline_value in zip(saved_log_probs, baseline_values):\n",
        "            policy_loss.append(-(log_prob * (R - baseline_value)))\n",
        "        policy_loss = torch.cat(policy_loss).sum()\n",
        "\n",
        "        # Update the policy\n",
        "        optimizer.zero_grad()\n",
        "        policy_loss.backward(retain_graph=True)  # Retain the computation graph\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the baseline\n",
        "        baseline_optimizer.zero_grad()\n",
        "        baseline_loss = ((baseline_values - R) ** 2).mean()\n",
        "        baseline_loss.backward()\n",
        "        baseline_optimizer.step()\n",
        "\n",
        "        if e % print_every == 0:\n",
        "            print('Episode {}\\tAverage Score: {:.2f}'.format(e, np.mean(scores_window)))\n",
        "        if np.mean(scores_window) >= 195.0:\n",
        "            print(f'Environment {env.unwrapped.spec.id} solved in {e - 100:d} episodes!\\tAverage Score: {np.mean(scores_window):.2f}')\n",
        "            break\n",
        "\n",
        "    return episode_list_epsgrdy, average_scores_epsgrdy\n",
        "\n",
        "\n",
        "# policy = Policy().to(device)\n",
        "# optimizer = optim.Adam(policy.parameters(), lr=1e-2)\n",
        "# baseline = Baseline(state_size=env.observation_space.shape[0]).to(device)\n",
        "# baseline_optimizer = optim.Adam(baseline.parameters(), lr=1e-2)\n",
        "# scores = reinforce(env, policy, optimizer, baseline, baseline_optimizer, n_episodes=2000)\n",
        "# wandb.finish()  # Finish wandb run"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=project_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247,
          "referenced_widgets": [
            "ec6a1f3a23304cfe8b3384c2133fb8d8",
            "cf601a707ebf4e329c2745604716bdc3",
            "6889d464afb34373ac5e976cb728ab39",
            "8036d050cadd4e3ea11b0af6c3515db1",
            "8f8d30d7a88147fe8dab0700e9bbe82b",
            "10597fc5e9a343e786cacd4cc5cb6cb6",
            "3f57fc3d4a76405591b06b214e331ef0",
            "29e6a8d0c8944a1c8553f7f3fe610a6e"
          ]
        },
        "id": "lI9JpNhurdWD",
        "outputId": "ed4e64c2-5b07-4015-dac2-de7606eba57f"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:uo1tnvh7) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec6a1f3a23304cfe8b3384c2133fb8d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">warm-durian-11</strong> at: <a href='https://wandb.ai/iitm_aero/RBCS2/runs/uo1tnvh7' target=\"_blank\">https://wandb.ai/iitm_aero/RBCS2/runs/uo1tnvh7</a><br/> View project at: <a href='https://wandb.ai/iitm_aero/RBCS2' target=\"_blank\">https://wandb.ai/iitm_aero/RBCS2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240409_051730-uo1tnvh7/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:uo1tnvh7). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240409_051828-jhj57cc9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/iitm_aero/RBCS2/runs/jhj57cc9' target=\"_blank\">true-snowflake-13</a></strong> to <a href='https://wandb.ai/iitm_aero/RBCS2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/iitm_aero/RBCS2' target=\"_blank\">https://wandb.ai/iitm_aero/RBCS2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/iitm_aero/RBCS2/runs/jhj57cc9' target=\"_blank\">https://wandb.ai/iitm_aero/RBCS2/runs/jhj57cc9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/iitm_aero/RBCS2/runs/jhj57cc9?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7ff5537c30d0>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# env = gym.make('CartPole-v1')\n",
        "# env.seed(0)\n",
        "# state_shape = env.observation_space.shape[0]\n",
        "# action_shape = env.action_space.n"
      ],
      "metadata": {
        "id": "nOKV8a9CnAec"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'metric': {\n",
        "      'name': 'Average Reward',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'state_size': {\n",
        "            'values': [state_shape]\n",
        "        },\n",
        "        'action_size': {\n",
        "            'values': [action_shape]\n",
        "        },\n",
        "        'hidden_size': {\n",
        "            'values': [64]\n",
        "        },\n",
        "        'max_t': {\n",
        "            'values': [1000]\n",
        "        },\n",
        "        'lr': {\n",
        "            'values': [1e-3]\n",
        "        },\n",
        "        'gamma': {\n",
        "            'values': [0.99]\n",
        "        },\n",
        "        'alpha': {\n",
        "            'values': [0.0001]\n",
        "        },\n",
        "        'n_episodes': {\n",
        "            'values': [2000]\n",
        "        },\n",
        "        \"max_t\":{\n",
        "            'values': [1000]\n",
        "        },\n",
        "         \"print_every\": {\n",
        "             'values': [100]\n",
        "         }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "Sn8tdcXc1Gte"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a new sweep\n",
        "sweep_id = wandb.sweep(sweep=sweep_config,  project=project_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QMZhG_F0TZB",
        "outputId": "db8a4b11-c305-4a74-f4bb-904cbe5aae70"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 4752uu5s\n",
            "Sweep URL: https://wandb.ai/iitm_aero/RBCS2/sweeps/4752uu5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6l21L1R-zZm4"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_scores = []"
      ],
      "metadata": {
        "id": "U8lTqmUvcJ4L"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AvgOverExperiments():\n",
        "\n",
        "    # with wandb.init() as run:\n",
        "        # Get the hyperparameters for this run\n",
        "        # config = wandb.config\n",
        "\n",
        "        # begin_time = datetime.datetime.now()\n",
        "        config= {\n",
        "        'state_size': state_shape,\n",
        "        'action_size':action_shape,\n",
        "        'hidden_size':64,\n",
        "        'max_t':1000,\n",
        "        'baseline_lr':1e-3,\n",
        "        'lr':1e-3,\n",
        "        'gamma':0.99,\n",
        "        'alpha':0.0001,\n",
        "        'n_episodes':2000,\n",
        "        \"max_t\": 1000,\n",
        "        \"print_every\": 100\n",
        "        }\n",
        "        # config = sweep_config\n",
        "        begin_time = datetime.datetime.now()\n",
        "        # Create the policy network with the specified hyperparameters\n",
        "        policy = Policy(state_size=4, action_size=2, hidden_size=config[\"hidden_size\"])\n",
        "        optimizer = optim.Adam(policy.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "\n",
        "        # Create the baseline network with the specified hyperparameters\n",
        "        baseline = Baseline(state_size=state_shape).to(device)\n",
        "        baseline_optimizer = optim.Adam(baseline.parameters(), lr=config[\"baseline_lr\"])\n",
        "\n",
        "\n",
        "        # Run the REINFORCE algorithm with the specified hyperparameters\n",
        "        episode_list_epsgrdy, average_scores_epsgrdy = reinforce(env, policy, optimizer, baseline, baseline_optimizer, n_episodes=config[\"n_episodes\"], max_t=config[\"max_t\"], gamma=config[\"gamma\"], print_every=config[\"print_every\"])\n",
        "\n",
        "        time_taken = datetime.datetime.now() - begin_time\n",
        "        print(time_taken)\n",
        "        # time_taken = datetime.datetime.now() - begin_time\n",
        "        print(average_scores_epsgrdy)\n",
        "        print('\\n')\n",
        "        average_scores.append(average_scores_epsgrdy)\n",
        "        # print(time_taken)\n",
        "        # Log the final average score to wandb\n",
        "        # wandb.log({\"Average Score\": average_scores_epsgrdy})\n",
        "        # wandb.log({\"Average Score\": cumulative_regret})\n"
      ],
      "metadata": {
        "id": "p9qbRfNIsXmV"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_avg_curves(avg_reward,reward_std, step_size = 1 ):\n",
        "\n",
        "    trunc_avg_reward = avg_reward[0::step_size]\n",
        "    tunc_reward_std = reward_std[0::step_size]\n",
        "\n",
        "    # trunc_avg_step = avg_step[0::step_size]\n",
        "    # tunc_step_std = step_std[0::step_size]\n",
        "\n",
        "    # Plot the average rewards with mean and standard deviation\n",
        "    plt.figure()\n",
        "    plt.plot(trunc_avg_reward, label='Mean')\n",
        "    plt.fill_between(range(step_size), trunc_avg_reward + tunc_reward_std, trunc_avg_reward - tunc_reward_std, alpha=0.5, label=' Std Dev')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Average Total Reward')\n",
        "    plt.title('Average Total Reward vs Episode')\n",
        "    plt.legend()\n",
        "    # plt.savefig( \"RvsE \" +\".pdf\")\n",
        "    # files.download(exp_no+\"_RvsE.png\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    # # Plot the average rewards with mean and standard deviation\n",
        "    # plt.figure()\n",
        "    # plt.plot(trunc_avg_step, label='Mean')\n",
        "    # plt.fill_between(range(step_size), trunc_avg_step + tunc_step_std, trunc_avg_step - tunc_step_std, alpha=0.5, label=' Std Dev')\n",
        "    # plt.xlabel('Episode')\n",
        "    # plt.ylabel('Average Regret')\n",
        "    # plt.title(' Average Regret vs Episode')\n",
        "    # plt.legend()\n",
        "    # # plt.savefig(\"SvsE \" + \".pdf\")\n",
        "    # # files.download(exp_no+\"_SvsE.png\")\n",
        "    # plt.show()\n",
        "\n",
        "    # # Plot the average rewards with mean and standard deviation\n",
        "    # plt.figure()\n",
        "    # plt.plot(avg_step, label='Mean')\n",
        "    # # plt.fill_between(range(step_size), trunc_avg_step + tunc_step_std, trunc_avg_step - tunc_step_std, alpha=0.5, label=' Std Dev')\n",
        "    # plt.xlabel('Episode')\n",
        "    # plt.ylabel('Cummulative Regret')\n",
        "    # plt.title('Cummulative Average Regret vs Episode')\n",
        "    # plt.legend()\n",
        "    # # plt.savefig(\"SvsE \" + \".pdf\")\n",
        "    # # files.download(exp_no+\"_SvsE.png\")\n",
        "    # plt.show()\n"
      ],
      "metadata": {
        "id": "bKMK9VnNK_-C"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Average over 5 exeriments\n",
        "\n",
        "# average_scores, cumm_regret = [], []\n",
        "num_expts = 5\n",
        "for i in range(num_expts):\n",
        "    AvgOverExperiments()\n",
        "    # print(\"Experiment: %d\" % (i + 1))\n",
        "    # # episode_average_scores, episode_cumm_regret =  wandb.agent(sweep_id, function=AvgOverExperiments, count=1)\n",
        "    # wandb.agent(sweep_id, function=AvgOverExperiments, count=1)\n",
        "    # # average_scores.append(episode_average_scores)\n",
        "    # # cumm_regret.append(episode_cumm_regret)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XVhKNa22FaH",
        "outputId": "448a9adf-8591-4517-f001-29c0125f2402"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100\tAverage Score: 19.97\n",
            "Episode 200\tAverage Score: 29.53\n",
            "Episode 300\tAverage Score: 40.59\n",
            "Episode 400\tAverage Score: 42.76\n",
            "Episode 500\tAverage Score: 52.89\n",
            "Episode 600\tAverage Score: 70.53\n",
            "Episode 700\tAverage Score: 70.74\n",
            "Episode 800\tAverage Score: 81.34\n",
            "Episode 900\tAverage Score: 98.61\n",
            "Episode 1000\tAverage Score: 107.87\n",
            "Episode 1100\tAverage Score: 170.08\n",
            "Environment CartPole-v1 solved in 1026 episodes!\tAverage Score: 195.02\n",
            "0:01:55.448281\n",
            "[195.02]\n",
            "\n",
            "\n",
            "Episode 100\tAverage Score: 25.83\n",
            "Episode 200\tAverage Score: 27.64\n",
            "Episode 300\tAverage Score: 32.70\n",
            "Episode 400\tAverage Score: 33.50\n",
            "Episode 500\tAverage Score: 41.09\n",
            "Episode 600\tAverage Score: 41.58\n",
            "Episode 700\tAverage Score: 48.87\n",
            "Episode 800\tAverage Score: 64.23\n",
            "Episode 900\tAverage Score: 68.69\n",
            "Episode 1000\tAverage Score: 104.74\n",
            "Episode 1100\tAverage Score: 134.19\n",
            "Episode 1200\tAverage Score: 170.33\n",
            "Environment CartPole-v1 solved in 1183 episodes!\tAverage Score: 199.06\n",
            "0:02:02.585020\n",
            "[199.06]\n",
            "\n",
            "\n",
            "Episode 100\tAverage Score: 25.79\n",
            "Episode 200\tAverage Score: 34.07\n",
            "Episode 300\tAverage Score: 43.94\n",
            "Episode 400\tAverage Score: 50.40\n",
            "Episode 500\tAverage Score: 59.96\n",
            "Episode 600\tAverage Score: 68.77\n",
            "Episode 700\tAverage Score: 84.87\n",
            "Episode 800\tAverage Score: 106.47\n",
            "Episode 900\tAverage Score: 142.87\n",
            "Episode 1000\tAverage Score: 179.83\n",
            "Environment CartPole-v1 solved in 940 episodes!\tAverage Score: 197.21\n",
            "0:01:50.749078\n",
            "[197.21]\n",
            "\n",
            "\n",
            "Episode 100\tAverage Score: 26.60\n",
            "Episode 200\tAverage Score: 39.18\n",
            "Episode 300\tAverage Score: 44.28\n",
            "Episode 400\tAverage Score: 48.04\n",
            "Episode 500\tAverage Score: 51.96\n",
            "Episode 600\tAverage Score: 57.43\n",
            "Episode 700\tAverage Score: 61.94\n",
            "Episode 800\tAverage Score: 71.72\n",
            "Episode 900\tAverage Score: 91.52\n",
            "Episode 1000\tAverage Score: 126.20\n",
            "Episode 1100\tAverage Score: 188.29\n",
            "Environment CartPole-v1 solved in 1004 episodes!\tAverage Score: 195.24\n",
            "0:01:41.886502\n",
            "[195.24]\n",
            "\n",
            "\n",
            "Episode 100\tAverage Score: 26.13\n",
            "Episode 200\tAverage Score: 26.46\n",
            "Episode 300\tAverage Score: 36.74\n",
            "Episode 400\tAverage Score: 39.95\n",
            "Episode 500\tAverage Score: 43.96\n",
            "Episode 600\tAverage Score: 47.96\n",
            "Episode 700\tAverage Score: 59.72\n",
            "Episode 800\tAverage Score: 59.03\n",
            "Episode 900\tAverage Score: 73.20\n",
            "Episode 1000\tAverage Score: 76.31\n",
            "Episode 1100\tAverage Score: 94.16\n",
            "Episode 1200\tAverage Score: 121.87\n",
            "Episode 1300\tAverage Score: 152.82\n",
            "Episode 1400\tAverage Score: 170.84\n",
            "Environment CartPole-v1 solved in 1366 episodes!\tAverage Score: 196.53\n",
            "0:02:22.910981\n",
            "[196.53]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_avg_curves(avg_reward, step_size=1):\n",
        "    max_length = max(len(reward) for reward in avg_reward)\n",
        "\n",
        "    # Initialize arrays to store sum and count of non-zero values for each index\n",
        "    sum_non_zero = np.zeros(max_length)\n",
        "    count_non_zero = np.zeros(max_length)\n",
        "\n",
        "    # Iterate over each list in avg_reward\n",
        "    for reward in avg_reward:\n",
        "        for j, value in enumerate(reward):\n",
        "            if j % step_size == 0:\n",
        "                sum_non_zero[j] += value\n",
        "                count_non_zero[j] += 1\n",
        "\n",
        "    # Calculate mean and standard deviation using non-zero values\n",
        "    mean_avg_reward = sum_non_zero / count_non_zero\n",
        "    mean_reward_std = np.zeros(max_length)\n",
        "\n",
        "    for reward in avg_reward:\n",
        "        for j, value in enumerate(reward):\n",
        "            if j % step_size == 0:\n",
        "                mean_reward_std[j] += (value - mean_avg_reward[j]) ** 2\n",
        "\n",
        "    mean_reward_std = np.sqrt(mean_reward_std / count_non_zero)\n",
        "\n",
        "    # Plot the average rewards with mean and standard deviation\n",
        "    plt.figure()\n",
        "    plt.plot(mean_avg_reward, label='Mean')\n",
        "    plt.fill_between(range(0, max_length, step_size), mean_avg_reward + mean_reward_std, mean_avg_reward - mean_reward_std, alpha=0.5, label=' Std Dev')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Average Total Reward')\n",
        "    plt.title('Average Total Reward vs Episode')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# average_scores = [[1, 2, 3], [4, 5, 6, 7], [8, 9]]\n",
        "\n",
        "plot_avg_curves(np.array(average_scores), step_size=1)\n"
      ],
      "metadata": {
        "id": "sOpWRBSMHrrw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}